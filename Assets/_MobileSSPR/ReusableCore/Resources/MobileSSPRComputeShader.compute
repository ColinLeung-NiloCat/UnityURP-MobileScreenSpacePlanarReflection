//see README here: https://github.com/ColinLeung-NiloCat/UnityURP-MobileScreenSpacePlanarReflection

//this is Mobile + Non-Mobile separated implementations of "Screen Space Planar Reflections in Ghost Recon Wildlands" using a single URP RendererFeature
//http://remi-genin.fr/blog/screen-space-plane-indexed-reflection-in-ghost-recon-wildlands/

//*we don't sample fallback reflection probe here, we sample it inside user's shader (e.g. water plane shader)
//because Lighting data provided by URP (e.g. reflection probe) is only correct when rendering using normal drawing method, but not correct in compute shader

//NUMTHREAD_X * NUMTHREAD_Y must be multiple of 64 and <= 256 to balance between performance and mobile support, so we use 8*8
#define NUMTHREAD_X 8
#define NUMTHREAD_Y 8

#define MAX_UINT 4294967295

#include "Packages/com.unity.render-pipelines.universal/ShaderLibrary/Core.hlsl"

//common SamplerState settings
SamplerState PointClampSampler;
SamplerState LinearClampSampler;

//common uniform input from MobileSSPRRendererFeature.cs
float2 _RTSize;
float _HorizontalPlaneHeightWS;
float _FadeOutScreenBorderWidthVerticle;
float _FadeOutScreenBorderWidthHorizontal; //compute shader can't declare half type input, so use float
float3 _CameraDirection;
//we found that on metal, UNITY_MATRIX_VP is not correct, so we will pass our own VP matrix to compute shader
//but UNITY_MATRIX_I_VP is correct, not sure why.
float4x4 _VPMatrix; 
float _ScreenLRStretchIntensity;
float _ScreenLRStretchThreshold;
float4 _FinalTintColor;

//common texture input from MobileSSPRRendererFeature.cs
RWTexture2D<half4> ColorRT;
Texture2D<half4> _CameraOpaqueTexture;
Texture2D<float> _CameraDepthTexture;

//Non-Mobile path will use this RT: single 32bits RInt RT, split first 16bits for GetReflectionColorFromID's y, last 16bits for GetReflectionColorFromID's x
//y put in first 16 bits because we want to sort by InterlockedMin(), allowing only "closer to reflection plane candidate" to write to HashRT
RWTexture2D<uint> HashRT; 

//Mobile(Android) path will use this RT: single 32bit float for posWSy
RWTexture2D<float> PosWSyRT;

////////////////////////////////////////////////////////////////////////////////////////////////////
// shared functions
////////////////////////////////////////////////////////////////////////////////////////////////////
float3 ConvertScreenIDToPosWS(uint2 id)
{
	//input id is compute function's input SV_DispatchThreadID
	float2 screenUV = float2(id.x / (_RTSize.x), id.y / (_RTSize.y)); //[0,RTSize-1] -> screen [0,1] uv
	float inputPixelRawDepth = _CameraDepthTexture.SampleLevel(PointClampSampler, screenUV, 0);//get rawDepth(posCS.z) in _CameraDepthTexture

	////////////////////////////////////////////////////////////////////////////////////////////////////
	//convert screenUV & _CameraDepthTexture's rawDepth(posCS.z) to posWS
	//https://github.com/Steven-Cannavan/URP_ScreenSpacePlanarReflections/blob/master/Assets/Shaders/ReflectionShader.compute#L75
	////////////////////////////////////////////////////////////////////////////////////////////////////
	float4 posCS = float4(screenUV * 2.0 - 1.0, inputPixelRawDepth, 1.0); //reconstruct posCS using screen [0,1] uv & rawDepth
#if UNITY_UV_STARTS_AT_TOP
	posCS.y = -posCS.y;
#endif
	
	float4 posHWS = mul(UNITY_MATRIX_I_VP, posCS); //posCS -> posHWS
	float3 posWS = posHWS.xyz / posHWS.w; //posHWS -> posWS

	return posWS;
}
float3 MirrorPosWS(float3 inputPosWS)
{
	float3 reflectedPosWS = inputPosWS;
	reflectedPosWS.y -= _HorizontalPlaneHeightWS;
	reflectedPosWS.y *= -1;//actual reflect action
	reflectedPosWS.y += _HorizontalPlaneHeightWS;

	return reflectedPosWS;
}
float2 ConvertReflectedPosWSToScreenUV(float3 reflectedPosWS)
{
	////////////////////////////////////////////////////////////////////////////////////////////////////
	//find reflected posWS's new screenUV
	//https://github.com/Steven-Cannavan/URP_ScreenSpacePlanarReflections/blob/master/Assets/Shaders/ReflectionShader.compute#L87
	////////////////////////////////////////////////////////////////////////////////////////////////////
	float4 reflectedPosCS = mul(_VPMatrix, float4(reflectedPosWS, 1));//posWS -> posCS
	float2 reflectedPosNDCxy = reflectedPosCS.xy / reflectedPosCS.w;//posCS -> posNDC

	float2 reflectedScreenUV = reflectedPosNDCxy * 0.5 + 0.5; //posNDC -> screen [0,1] uv, don't saturate() to allow  out of bound access early exit

	////////////////////////////////////////////////////////////////////////////////////////////////////
	//fix left right missing geometry 
	//ref: http://remi-genin.fr/blog/screen-space-plane-indexed-reflection-in-ghost-recon-wildlands/#filling-the-gaps-jump
	////////////////////////////////////////////////////////////////////////////////////////////////////
	//sample code from http://remi-genin.fr/blog/screen-space-plane-indexed-reflection-in-ghost-recon-wildlands/#filling-the-gaps-jump
	/*
	float HeightStretch = (PosWS.z - WaterHeight);
	float AngleStretch = saturate(- CameraDirection.z);
	float ScreenStretch = saturate(abs(ReflPosUV.x * 2 - 1) - Threshold);

	ReflPosUV.x *= 1 + HeightStretch * AngleStretch * ScreenStretch * Intensity;
	*/

	//TODO: better fill LeftRight
	float Threshold = _ScreenLRStretchThreshold;
	float Intensity = _ScreenLRStretchIntensity;

	float HeightStretch = (abs(reflectedPosWS.y - _HorizontalPlaneHeightWS));
	float AngleStretch = (-_CameraDirection.y);
	float ScreenStretch = saturate(abs(reflectedScreenUV.x * 2 - 1) - Threshold);

	reflectedScreenUV.x = reflectedScreenUV.x * 2 - 1;
	reflectedScreenUV.x *= 1 + HeightStretch * AngleStretch * ScreenStretch * Intensity;
	reflectedScreenUV.x = saturate(reflectedScreenUV.x * 0.5 + 0.5);
	
	////////////////////////////////////////////////////////////////////////////////////////////////////
	//flip UV according to platform 
	//ref: https://github.com/Steven-Cannavan/URP_ScreenSpacePlanarReflections/blob/master/Assets/Shaders/ReflectionShader.compute#L95
	////////////////////////////////////////////////////////////////////////////////////////////////////
#if UNITY_UV_STARTS_AT_TOP
	reflectedScreenUV.y = 1.0 - reflectedScreenUV.y;
#endif

	return reflectedScreenUV;
}
half ConvertOpaqueColorRTScreenUVToFadeAlphaParam(float2 screenUV, float reflectedPosWSy)
{
	//fadeout  using vertical uv.y (only fadeout if reaching _CameraOpaqueTexture's uv border top)
	half fadeoutAlpha = smoothstep(1, 1-_FadeOutScreenBorderWidthVerticle, screenUV.y);
	//fadeout using horizontal uv.x
	//TODO: better fadeout
	fadeoutAlpha *= smoothstep(1, 1 - _FadeOutScreenBorderWidthHorizontal * -(reflectedPosWSy-_HorizontalPlaneHeightWS), abs(screenUV.x * 2 - 1));
	return fadeoutAlpha;
}

////////////////////////////////////////////////////////////////////////////////////////////////////
// kernel: NonMobilePathClear
////////////////////////////////////////////////////////////////////////////////////////////////////
#pragma kernel NonMobilePathClear

[numthreads(NUMTHREAD_X, NUMTHREAD_Y, 1)]
void NonMobilePathClear(uint3 id : SV_DispatchThreadID)
{
	HashRT[id.xy] = MAX_UINT; //max value as clear, because we want to sort by InterlockedMin()
	ColorRT[uint2(id.xy)] = half4(0, 0, 0, 0);
}


////////////////////////////////////////////////////////////////////////////////////////////////////
// kernel: NonMobilePathRenderHashRT
////////////////////////////////////////////////////////////////////////////////////////////////////
#pragma kernel NonMobilePathRenderHashRT

[numthreads(NUMTHREAD_X,NUMTHREAD_Y,1)]
void NonMobilePathRenderHashRT(uint3 id : SV_DispatchThreadID)
{
	////////////////////////////////////////////////////////////////////////////////////////////////////
	//ConvertScreenIDToPosWS
	////////////////////////////////////////////////////////////////////////////////////////////////////
	float3 posWS = ConvertScreenIDToPosWS(id);

	////////////////////////////////////////////////////////////////////////////////////////////////////
	//if posWS is already under reflection plane (e.g. under water plane), 
	//it will never be a correct color to reflect anyway, early exit to prevent wrong result write to Color RT
	////////////////////////////////////////////////////////////////////////////////////////////////////
	if(posWS.y <= _HorizontalPlaneHeightWS)
		return;

	////////////////////////////////////////////////////////////////////////////////////////////////////
	//mirror posWS according to horizontal reflection plane (e.g. water plane)
	////////////////////////////////////////////////////////////////////////////////////////////////////
	float3 reflectedPosWS = MirrorPosWS(posWS);

	////////////////////////////////////////////////////////////////////////////////////////////////////
	//ConvertReflectedPosWSToScreenID
	////////////////////////////////////////////////////////////////////////////////////////////////////
	float2 reflectedScreenUV = ConvertReflectedPosWSToScreenUV(reflectedPosWS);
	//early exit if not valid uv anymore, to avoid out of bound access
	float2 earlyExitTest = abs(reflectedScreenUV - 0.5);
	if (earlyExitTest.x >= 0.5 || earlyExitTest.y >= 0.5)
		return;
	uint2 reflectedScreenID = reflectedScreenUV * _RTSize;//from screen uv[0,1] to [0,RTSize-1]

	////////////////////////////////////////////////////////////////////////////////////////////////////
	//write "original RT position ID.xy and alpha" as "12bit yID,12bit xID, 8bit alpha" hash at location "reflected RT position"
	////////////////////////////////////////////////////////////////////////////////////////////////////
	/*
	ref: http://remi-genin.fr/blog/screen-space-plane-indexed-reflection-in-ghost-recon-wildlands/#hash-resolve-jump
	Read-write max when accessing the projection hash UAV

	//sample code from above site, "Hash resolve" section
	uint projectionHash = SrcPosPixel.y << 16 | SrcPosPixel.x; 
	InterlockedMax(ProjectionHashUAV[ReflPosPixel], projectionHash, dontCare);
	*/

	//ghost-recon-wildlands method use 16bit y, 16bit x encode
	//but in our implementation, 16bit is overkill because we don't need a RT that is 65536*65536
	//instead we save 8 bits for fadeout alpha info, result in:
	//-first 12 bits for id.y (0~4095)
	//-then  12 bits for id.x (0~4095)
	//-last  8  bits for alpha (0~255)
	float2 screenUV = id.xy / _RTSize;
	half fadeoutAlpha = ConvertOpaqueColorRTScreenUVToFadeAlphaParam(screenUV, reflectedPosWS.y);

	uint fadeoutAlphaInt = fadeoutAlpha * 255;//8 bit
	uint hash = id.y << 20 | id.x << 8 | fadeoutAlphaInt; //pack 3 uint into 1
#if SHADER_API_METAL
	//do nothing because metal will never use this kernel (NonMobile kernel)
#else
	InterlockedMin(HashRT[reflectedScreenID],hash); //correct sorting method, sort by id.y
#endif
	//HashRT[reflectedScreenID] = hash; //no sorting method, don't use it, it will produce random flickering because of unknown order write(random order)
}


////////////////////////////////////////////////////////////////////////////////////////////////////
// kernel NonMobilePathResolveColorRT
////////////////////////////////////////////////////////////////////////////////////////////////////
#pragma kernel NonMobilePathResolveColorRT

[numthreads(NUMTHREAD_X, NUMTHREAD_Y, 1)]
void NonMobilePathResolveColorRT(uint3 id : SV_DispatchThreadID)
{
	/*
	//ref code
	//http://remi-genin.fr/blog/screen-space-plane-indexed-reflection-in-ghost-recon-wildlands/#hash-resolve-jump
	
	float4 PS_ResolveHash(float2 ScreenUV) : SV_Target0
	{
		uint Hash = ProjectionHashTex[ScreenUV * FrameSize].x;
		uint x = Hash & 0xFFFF; uint y = Hash >> 16;

		if(Hash != 0)
		{
			float4 SrcColor = MainColorTex[uint2(x, y)];
			return SrcColor;
		}
		else
			return 0;
	}
	*/
	uint packedData = HashRT[id.xy];	
	if (packedData == MAX_UINT) //MAX_UINT == max uint
	{
		//if this location is not having any reflection data (still containing clear value, still 0 reflection write), early exit to prevent wrong RT write
		ColorRT[id.xy] = 0;
		return;
	}	

	//ghost-recon-wildlands method use 16bit y, 16bit x encode
	//but in our implementation, 16bit is overkill because we don't need a RT that is 65536*65536
	//instead we save 8 bits for fadeout alpha info, result in:
	//-first 12 bits for id.y (0~4095)
	//-then  12 bits for id.x (0~4095)
	//-last  8  bits for alpha (0~255)
	uint2 sampleID = uint2((packedData >> 8) & 0xFFF, packedData >> 20); //decode from single 32bit uint, to 3 separated uint (12bit y & 12bit x & 8bit alpha)
	uint alphaAsInt = packedData & 0xFF;
	half alphaAsFloatingPoint = alphaAsInt / 255.0;

	float2 sampleUV = sampleID.xy / _RTSize;
	half3 sampledColor = _CameraOpaqueTexture.SampleLevel(LinearClampSampler, sampleUV, 0);

	half4 finalColor = half4(sampledColor, alphaAsFloatingPoint) * _FinalTintColor;
	finalColor.a = saturate(finalColor.a);
	ColorRT[id.xy] = finalColor;
}


////////////////////////////////////////////////////////////////////////////////////////////////////
// kernel MobilePathSinglePassColorRTDirectResolve
////////////////////////////////////////////////////////////////////////////////////////////////////
#pragma kernel MobilePathSinglePassColorRTDirectResolve

[numthreads(NUMTHREAD_X,NUMTHREAD_Y,1)]
void MobilePathSinglePassColorRTDirectResolve(uint3 id : SV_DispatchThreadID)
{
	////////////////////////////////////////////////////////////////////////////////////////////////////
	//Clear
	////////////////////////////////////////////////////////////////////////////////////////////////////
    ColorRT[uint2(id.xy)] = half4(0,0,0,0);//black rgb and alpha = 0. alpha 0 means no valid SSPR pixels found, so reflection plane will not use SSRP's result     
    PosWSyRT[uint2(id.xy)] = 9999999;//a very high posWS.y as clear value

	////////////////////////////////////////////////////////////////////////////////////////////////////
	//ConvertScreenIDToPosWS
	////////////////////////////////////////////////////////////////////////////////////////////////////
	float3 posWS = ConvertScreenIDToPosWS(id);

	////////////////////////////////////////////////////////////////////////////////////////////////////
	//if posWS is already under reflection plane (e.g. under water plane), 
	//it will never be a correct color to reflect anyway, early exit to prevent wrong result write to Color RT
	////////////////////////////////////////////////////////////////////////////////////////////////////
	if(posWS.y <= _HorizontalPlaneHeightWS)
		return;

	////////////////////////////////////////////////////////////////////////////////////////////////////
	//mirror posWS according to horizontal reflection plane (e.g. water plane)
	////////////////////////////////////////////////////////////////////////////////////////////////////
	float3 reflectedPosWS = MirrorPosWS(posWS);

	////////////////////////////////////////////////////////////////////////////////////////////////////
	//ConvertReflectedPosWSToScreenID
	////////////////////////////////////////////////////////////////////////////////////////////////////
	float2 reflectedScreenUV = ConvertReflectedPosWSToScreenUV(reflectedPosWS);
	//early exit if not valid uv anymore, to avoid out of bound access
	float2 earlyExitTest = abs(reflectedScreenUV - 0.5);
	if (earlyExitTest.x >= 0.5 || earlyExitTest.y >= 0.5) 
		return;
	uint2 reflectedScreenID = reflectedScreenUV * _RTSize;//from screen uv[0,1] to [0,RTSize-1]
	
	//because writes to ColorRT are in an unknown random order(there can be >1 candidates writing to the same slot in the same dispatch call!),
	//here we only allow "closer to horizontal reflection plane's candidate" to write to ColorRT & PosWSyRT.
	//At the end, only the "closest to horizontal reflection plane candidate" will remain in ColorRT & PosWSyRT, which is the correct reflection data
	if(posWS.y < PosWSyRT[reflectedScreenID])
	{
		float2 screenUV = id.xy / _RTSize;
		half3 inputPixelSceneColor = _CameraOpaqueTexture.SampleLevel(LinearClampSampler, screenUV, 0).rgb;

		half fadeoutAlpha = ConvertOpaqueColorRTScreenUVToFadeAlphaParam(screenUV, reflectedPosWS.y);

		//we write the following data to 2 RTs:
		//-ColorRT.rgba = current best reflection color and alpha(alpha means SSPR usage %)
		//-PosWSyRT.r = current lowest PosyWS (concept similar to a regular depth buffer ZTest->ZWrite)
		half4 color = half4(inputPixelSceneColor,fadeoutAlpha) * _FinalTintColor;
		color.a = saturate(color.a);
		ColorRT[reflectedScreenID] = color;
		PosWSyRT[reflectedScreenID] = posWS.y;
	}
}


////////////////////////////////////////////////////////////////////////////////////////////////////
// kernel FillHoles
////////////////////////////////////////////////////////////////////////////////////////////////////
#pragma kernel FillHoles

[numthreads(NUMTHREAD_X, NUMTHREAD_Y, 1)]
void FillHoles(uint3 id : SV_DispatchThreadID)
{
	//fill holes inside each 2*2
	id.xy *= 2;

	//cache read
	half4 center = ColorRT[id.xy + uint2(0, 0)];
	half4 right = ColorRT[id.xy + uint2(0, 1)];
	half4 bottom = ColorRT[id.xy + uint2(1, 0)];
	half4 bottomRight = ColorRT[id.xy + uint2(1, 1)];

	//find best inside 2*2
	half4 best = center;
	best = right.a > best.a + 0.5 ? right : best;
	best = bottom.a > best.a + 0.5 ? bottom : best;
	best = bottomRight.a > best.a + 0.5 ? bottomRight : best;

	//write better rgba
	ColorRT[id.xy + uint2(0, 0)] = best.a > center.a + 0.5 ? best : center;
	ColorRT[id.xy + uint2(0, 1)] = best.a > right.a + 0.5 ? best : right;
	ColorRT[id.xy + uint2(1, 0)] = best.a > bottom.a + 0.5 ? best : bottom;
	ColorRT[id.xy + uint2(1, 1)] = best.a > bottomRight.a + 0.5 ? best : bottomRight;
}